{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f383a5b-4da9-4141-a2f5-dfb68b835a07",
   "metadata": {},
   "source": [
    "# Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725fd7f-24a2-4afe-bf07-0c24807b2d7c",
   "metadata": {},
   "source": [
    "# Big O Notation \n",
    "\n",
    "- A generalized was to catergorize your algorithm's time or memory requirements based on how input grows.\n",
    "- It is not meant to be exact, and focuses on worst case. \n",
    "- It helps us make decisions between data structures based on how they will perform in various circumstances.\n",
    "\n",
    "### Main Concepts\n",
    "1. Growth is with respect to the input\n",
    "2. Constants are dropped\n",
    "3. Worst case is usually the way we measure\n",
    "\n",
    "### Dileneations (ascending) \n",
    "- O(1) : constant time\n",
    "- O(logn) : base two, smaller by half each time. grows linearly\n",
    "- O(n) : linear time\n",
    "- O(nlogn) : (quicksort) half the amount of data, go all the way through that, repeat. \n",
    "- O(n^2) : exponential \n",
    "- O(2^n) : exponential, much steeper\n",
    "\n",
    "- Honorable mention: O(sqrt(n)) - very rare, two crystal ball problem\n",
    "\n",
    "![Big O](bigo.png)\n",
    "\n",
    "### Calculating Big O \n",
    "- The simplest and most straight forward way to calculate is to look for loops. ( Very basic approach here )\n",
    "- We do not count constants when calculating O(n).\n",
    "- Say we have two consecutive for loops, that would be 0(2n), but we simply drop the constant (2) \n",
    "- Our main concern here is seeing how an algorithm will grow. Thus, when comparing something like O(10n) with O(n^2), the latter will start to grow disproportionately large to the point where the constant wouldn't matter anyway. This is true across the various dileniations of Big O.\n",
    "\n",
    "### Practical Considerations \n",
    "- Just because O(n) is faster than O(n^2) generally, it may not hold true for smaller input. Thus, we must consider our intended data size when considering a certain algorithm and not just rely entirely on the high level concepts.\n",
    "- The best practice with Big O however is to always describe the worst case. Very rarely are we concerned with best or average.\n",
    "- There are other ways to calculate time, but Big O is the most popular.\n",
    "- Big O can also measure space, though this consideration is quite rare. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6bb81c-b2f6-4cab-8111-ccbe746f1267",
   "metadata": {},
   "source": [
    "# Arrays \n",
    "\n",
    "## General \n",
    "- At a high level, an array is a single contiguous allocation in memory.\n",
    "- It is then broken up according to the type of data it will contain.\n",
    "- From there, the data can be accessed according to index, which is essentially a way to \"walk\" through each allocated memory space according to it's size (offset)\n",
    "- NOTE: Arrays are contiguous spaces in memory, Lists are not. Arrays != Lists\n",
    "- Fixed size, cannot grow. No way. \n",
    "\n",
    "## Example \n",
    "1. Allocate an \"Array Buffer\" (js) of byte length 6\n",
    "2. Create an 8 bit array using the array buffer (6 x 8bit spaces)\n",
    "3. Assign index 0 and index 2. We see that these are assigned to their respective locations in the array.\n",
    "4. Reassign the original array buffer to 16 bit (3 x 16 bit spaces)\n",
    "5. Now, we see that the index assignment is cut in half for the space.\n",
    "\n",
    "This shows us a contiguous memory space that is interpreted in two different ways. \n",
    "\n",
    "## Mechanics\n",
    "- Insertion: When we are inserting into an Array position, we are essentially overwriting that space, which has been initialized in a certain manner. We can go straight to this address because it will  be the index multiplied by the offset of the data type. \n",
    "- Deletion: We don't delete out of contiguous memory. Rather, we set this space to a new value that denotes \"deletion\". Perhaps setting to a 0, -1, null, etc. In the case of Array, this could also look like overwriting by shifting the array by 1.\n",
    "- At a basic level, the length of the array in terms of saved values, also need to be maintained. It simply represents the amount of the array that has been assigned, where the remainder will be allocated with values that represent \"unassigned\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecba72-17b7-4a32-a898-1f7ad11a88c5",
   "metadata": {},
   "source": [
    "# Extra Tip for the course\n",
    "- Being able to visualize the problem and draw it before implementing it is a core competency. This is an extremely valuable skill to have that will stick with you the rest of your career. Eventually, you can start to do this in your head. Eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4ffd9-7fd7-44fa-8a4f-6ec6507a0704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
